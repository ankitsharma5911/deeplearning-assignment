{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is a Convolutional Neural Network (CNN), and why is it used for image processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a CNN?\n",
    "A Convolutional Neural Network (CNN) is a class of deep learning models that is particularly effective for image processing tasks.\n",
    "A CNN is designed to automatically and adaptively learn spatial hierarchies of features from input images. It’s made up of several layers, primarily:\n",
    "\n",
    "* **Convolutional Layers:** These layers apply a convolution operation to the input, passing the result to the next layer. This step is designed to detect local patterns such as edges, textures, and shapes.\n",
    "\n",
    "* **Pooling Layers:** These layers reduce the dimensionality of the feature maps, which helps in reducing computational complexity and helps in extracting dominant features that are invariant to translation.\n",
    "\n",
    "* **Fully Connected Layers:** These layers act as a classifier on top of the extracted features, assigning class scores to input images.\n",
    "\n",
    "#### Why is it used for Image Processing?\n",
    "Automatic Feature Extraction: CNNs automatically and adaptively learn spatial hierarchies of features, which means they can detect simple patterns in earlier layers and more complex patterns in deeper layers.\n",
    "\n",
    "* **Parameter Sharing:** Convolutional layers share parameters across space, which means the same filter (or neuron) is applied to different parts of the input image. This significantly reduces the number of parameters and computational load.\n",
    "\n",
    "* **Translation Invariance:** Because of the local receptive fields and pooling layers, CNNs can recognize objects in an image regardless of their position, making them robust to translations of the input images.\n",
    "\n",
    "* **Efficiency:** CNNs reduce the need for manual feature extraction and are more efficient in terms of computation and memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the key components of a CNN architecture ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Components\n",
    "\n",
    "1. **Input Layer**:\n",
    "    - The image or input data is fed into this layer, typically in the form of a tensor with dimensions representing width, height, and the number of channels (e.g., RGB).\n",
    "\n",
    "2. **Convolutional Layer (Conv Layer)**:\n",
    "    - **Filters/Kernels**: Small matrices (e.g., 3x3, 5x5) that slide over the input image to detect features. The depth of the filter corresponds to the number of channels in the input.\n",
    "    - **Stride**: The number of pixels by which the filter moves. Larger strides reduce the spatial dimensions of the output.\n",
    "    - **Padding**: Adding zeros around the borders of the input to maintain the spatial dimensions.\n",
    "\n",
    "3. **Activation Function**:\n",
    "    - **ReLU (Rectified Linear Unit)**: A non-linear activation function applied element-wise to the output of the convolutional layer. It introduces non-linearity to the model.\n",
    "\n",
    "4. **Pooling Layer**:\n",
    "    - **Max Pooling**: Selects the maximum value from a patch of the feature map. Commonly used to reduce spatial dimensions and computation.\n",
    "    - **Average Pooling**: Computes the average value of a patch in the feature map.\n",
    "\n",
    "5. **Fully Connected Layer (Dense Layer)**:\n",
    "    - After several convolutional and pooling layers, the high-level reasoning in the network is done via fully connected layers. Here, every node is connected to every other node in the previous layer.\n",
    "  \n",
    "6. **Output Layer**:\n",
    "    - The final layer of the network that produces the output. In classification tasks, this layer uses an activation function like Softmax to output probabilities for each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What is the role of the convolutional layer in CNNs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional layer is the heart of a Convolutional Neural Network (CNN) and plays a critical role in feature extraction from the input image.\n",
    "\n",
    "### Role of the Convolutional Layer\n",
    "\n",
    "1. **Feature Extraction**:\n",
    "    - The primary role of the convolutional layer is to detect local patterns in the input data. This is achieved through the use of filters (or kernels) that slide over the input image to create feature maps.\n",
    "\n",
    "2. **Filters/Kernels**:\n",
    "    - Filters are small matrices that, when applied to the input image, perform a convolution operation. Each filter is designed to recognize specific features such as edges, corners, and textures. For example, one filter might highlight vertical edges, while another might highlight horizontal edges.\n",
    "\n",
    "3. **Convolution Operation**:\n",
    "    - The filter is slid (or convolved) across the entire input image. At each position, the filter’s values are multiplied by the corresponding pixel values of the input image, and the results are summed to produce a single output value in the feature map. This operation is repeated for each filter and for each region of the input image.\n",
    "\n",
    "4. **Preservation of Spatial Relationships**:\n",
    "    - The convolution operation helps preserve the spatial relationships between pixels by learning the dependencies between neighboring pixels. This is crucial for tasks like image recognition where the position of features matters.\n",
    "\n",
    "5. **Parameter Sharing and Sparsity of Connections**:\n",
    "    - In a convolutional layer, the same filter is used across the entire image. This means that the number of parameters is significantly reduced compared to a fully connected layer, making the network more efficient and less prone to overfitting. Additionally, each filter only interacts with a small local region of the input image, which introduces sparsity of connections.\n",
    "\n",
    "### Key Terms\n",
    "\n",
    "- **Stride**: The number of pixels by which the filter moves across the input image. Larger strides reduce the spatial dimensions of the output but can also skip over important details.\n",
    "- **Padding**: Adding extra pixels around the border of the input image to control the spatial dimensions of the output feature map. Common padding types are “valid” (no padding) and “same” (padding such that the output has the same dimensions as the input).\n",
    "\n",
    "### Importance in CNNs\n",
    "\n",
    "- **Hierarchical Feature Learning**: Convolutional layers allow CNNs to learn hierarchical representations of the input data. Early layers might detect simple features like edges, while deeper layers can detect more complex features like shapes and objects.\n",
    "- **Translation Invariance**: By using convolutional layers, CNNs become more robust to translations of the input image. This means that an object can be recognized regardless of where it appears in the image.\n",
    "- **Efficiency**: Convolutional layers greatly reduce the computational complexity and memory usage compared to fully connected layers, making them suitable for processing high-dimensional data like images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is a filter (kernel) in CNNs ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filters are small matrices that, when applied to the input image, perform a convolution operation. Each filter is designed to recognize specific features such as edges, corners, and textures. For example, one filter might highlight vertical edges, while another might highlight horizontal edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is pooling in CNNs, and why is it important ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling in Convolutional Neural Networks (CNNs) is a down-sampling operation that reduces the spatial dimensions (height and width) of the input feature maps, thereby decreasing the number of parameters and the computational load in the network. It plays a crucial role in controlling overfitting and makes the detection of features invariant to small translations of the input.\n",
    "\n",
    "### Importance of Pooling\n",
    "\n",
    "1. **Dimensionality Reduction**:\n",
    "    - Pooling layers reduce the spatial size of the feature maps, which lowers the number of parameters and computations in the network, making it more efficient.\n",
    "\n",
    "2. **Translation Invariance**:\n",
    "    - By down-sampling, pooling layers make the network more robust to slight translations of the input image, enhancing the ability to recognize objects regardless of their position.\n",
    "\n",
    "3. **Feature Consolidation**:\n",
    "    - Pooling helps in summarizing and consolidating the features detected by the convolutional layers, ensuring that the important features are retained.\n",
    "\n",
    "4. **Reduction of Overfitting**:\n",
    "    - By reducing the complexity of the network, pooling layers help prevent overfitting, which is especially useful when dealing with smaller datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What are the common types of pooling used in CNNs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Pooling\n",
    "\n",
    "1. **Max Pooling**:\n",
    "    - **Operation**: Selects the maximum value from each patch of the feature map.\n",
    "    - **Effect**: Captures the most prominent feature in each patch.\n",
    "\n",
    "2. **Average Pooling**:\n",
    "    - **Operation**: Computes the average value from each patch of the feature map.\n",
    "    - **Effect**: Provides smoother representations by averaging features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How does the backpropagation algorithm work in CNNs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation is a fundamental algorithm used for training neural networks, including Convolutional Neural Networks (CNNs). It involves computing the gradient of the loss function with respect to each weight by the chain rule, allowing the efficient calculation of the gradient.\n",
    "\n",
    "#### How Backpropagation Works in CNNs:\n",
    "\n",
    "1. **Forward Pass**:\n",
    "    - The input image is fed into the CNN, and the data passes through each layer (convolutional, pooling, and fully connected) until it reaches the output layer.\n",
    "    - During this process, activations (outputs) are calculated for each neuron in the network.\n",
    "\n",
    "2. **Loss Calculation**:\n",
    "    - The network’s output is compared to the true label using a loss function (e.g., cross-entropy loss for classification tasks).\n",
    "    - The loss function quantifies the difference between the predicted output and the actual output.\n",
    "\n",
    "3. **Backward Pass** (Gradient Computation):\n",
    "    - The goal is to minimize the loss, so the algorithm computes the gradient of the loss function with respect to each weight in the network.\n",
    "    - This is done by propagating the error backward through the network, starting from the output layer and moving back to the input layer.\n",
    "\n",
    "#### Steps in the Backward Pass:\n",
    "\n",
    "1. **Output Layer**:\n",
    "    - Compute the gradient of the loss function with respect to the output layer’s activations.\n",
    "    - Use this gradient to compute the gradient of the loss with respect to the weights and biases in the output layer.\n",
    "\n",
    "2. **Fully Connected Layers**:\n",
    "    - Propagate the gradient backward through the fully connected layers.\n",
    "    - For each layer, compute the gradient of the loss with respect to the weights and biases, and also with respect to the previous layer’s activations.\n",
    "\n",
    "3. **Pooling Layers**:\n",
    "    - In pooling layers (e.g., max pooling), the gradient is passed back to the locations that contributed to the max value.\n",
    "    - For average pooling, the gradient is uniformly distributed to all inputs that contributed to the average.\n",
    "\n",
    "4. **Convolutional Layers**:\n",
    "    - Compute the gradient of the loss with respect to the feature maps (outputs of the convolutional layer).\n",
    "    - Use this to compute the gradient of the loss with respect to the filters (kernels) and biases.\n",
    "    - The convolutional layer’s gradients are computed using the chain rule, taking into account the stride, padding, and the filters.\n",
    "\n",
    "#### Weight Update:\n",
    "\n",
    "- Once the gradients are computed for all layers, the weights are updated using an optimization algorithm, such as Stochastic Gradient Descent (SGD).\n",
    "- The weights are adjusted by a small amount proportional to the negative of the gradient (to minimize the loss).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. What is the role of activation functions in CNNs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions are critical components in Convolutional Neural Networks (CNNs) and other neural networks. Their main role is to introduce non-linearity into the network, allowing it to learn and model complex patterns in the data.\n",
    "\n",
    "### Key Roles of Activation Functions in CNNs\n",
    "\n",
    "1. **Introducing Non-Linearity**:\n",
    "    - Activation functions like ReLU (Rectified Linear Unit) introduce non-linear properties to the network. Without non-linearity, a neural network would simply be equivalent to a single-layer perceptron and unable to model complex data.\n",
    "\n",
    "2. **Enabling Complex Pattern Learning**:\n",
    "    - By introducing non-linearities, activation functions enable CNNs to learn and represent complex patterns and relationships in the data. This is crucial for tasks such as image recognition, where the data is inherently non-linear.\n",
    "\n",
    "3. **Controlling Neuron Activation**:\n",
    "    - Activation functions decide whether a neuron should be activated or not based on the input. Functions like ReLU allow for sparse activation, meaning only a subset of neurons are activated at any given time, which can make the network more efficient.\n",
    "\n",
    "### Common Activation Functions in CNNs\n",
    "\n",
    "1. **ReLU (Rectified Linear Unit)**\n",
    "2. **Leaky ReLU**\n",
    "3. **Sigmoid**\n",
    "4. **Tanh (Hyperbolic Tangent)**\n",
    "5. **Softmax**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. What is the concept of receptive fields in CNNs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of receptive fields is fundamental in Convolutional Neural Networks (CNNs) and plays a crucial role in understanding how these networks process spatial information in images.\n",
    "\n",
    "#### Receptive Fields Explained\n",
    "\n",
    "1. **Definition**:\n",
    "    - The receptive field of a neuron in a CNN refers to the specific region of the input image that influences the activation of that neuron. In other words, it is the area of the input image to which a particular filter or neuron is responsive.\n",
    "\n",
    "2. **Local Receptive Fields**:\n",
    "    - In the early layers of a CNN, neurons have small receptive fields that cover local patches of the input image. These small regions allow the network to capture fine-grained details like edges and textures.\n",
    "\n",
    "3. **Increasing Size in Deeper Layers**:\n",
    "    - As we move deeper into the network, the receptive fields of neurons become larger due to the cumulative effect of multiple convolutional and pooling layers. This allows deeper layers to capture more complex features and broader spatial patterns.\n",
    "\n",
    "4. **Hierarchical Feature Learning**:\n",
    "    - The receptive field concept allows CNNs to build a hierarchy of features. Early layers detect basic features (e.g., edges), while deeper layers detect more complex structures (e.g., parts of objects) and even entire objects, thanks to the increasing receptive field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Explain the concept of tensor space in CNNs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of Convolutional Neural Networks (CNNs), the term \"tensor space\" is often used to describe the multi-dimensional arrays of data that are processed by the network. Tensors are the generalization of scalars, vectors, and matrices to higher dimensions, and they play a fundamental role in deep learning frameworks.\n",
    "\n",
    "#### Key Concepts of Tensor Space in CNNs\n",
    "\n",
    "1. **Definition of a Tensor**:\n",
    "    - A tensor is a multi-dimensional array that can represent various types of data. For example:\n",
    "        - A **scalar** (0-dimensional tensor) is a single number.\n",
    "        - A **vector** (1-dimensional tensor) is an array of numbers.\n",
    "        - A **matrix** (2-dimensional tensor) is a grid of numbers.\n",
    "        - A tensor with more than two dimensions is referred to as a higher-order tensor.\n",
    "\n",
    "2. **Representation in CNNs**:\n",
    "    - In CNNs, tensors are used to represent the input data, the weights, the biases, and the feature maps at each layer. For instance:\n",
    "        - The input image is represented as a 3D tensor with dimensions corresponding to height, width, and the number of channels (e.g., RGB channels for a color image).\n",
    "        - The output of convolutional layers, known as feature maps, are also 3D tensors, with dimensions for height, width, and the number of filters (feature channels).\n",
    "\n",
    "3. **Tensor Operations in CNNs**:\n",
    "    - **Convolution**: This operation involves sliding a filter (a smaller tensor) over the input tensor (image) to produce a feature map. The result of the convolution operation is another tensor.\n",
    "    - **Pooling**: Pooling operations (e.g., max pooling) are applied to tensors to reduce their spatial dimensions while retaining important features. This results in a new tensor with smaller spatial dimensions.\n",
    "    - **Activation**: Applying an activation function element-wise to the tensors introduces non-linearity into the network.\n",
    "\n",
    "4. **Tensor Shape and Dimensions**:\n",
    "    - The shape of a tensor is defined by the number of elements in each dimension. For example, an input image tensor with shape (32, 32, 3) has 32 pixels in height, 32 pixels in width, and 3 color channels.\n",
    "    - The dimensions of tensors change as they pass through different layers of the CNN due to operations like convolution and pooling.\n",
    "\n",
    "5. **Batch Processing**:\n",
    "    - During training and inference, multiple input examples are often processed together in batches. Each batch is represented as a 4D tensor with dimensions corresponding to the number of examples in the batch, height, width, and number of channels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. What is LeNet-5, and how does it contribute to the development of CNNs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 is one of the pioneering Convolutional Neural Network (CNN) architectures, developed by Yann LeCun and his colleagues in the late 1980s and early 1990s. It was primarily designed for handwritten digit recognition in the MNIST dataset. LeNet-5 played a critical role in the development and popularization of CNNs.\n",
    "\n",
    "### Key Components of LeNet-5\n",
    "\n",
    "1. **Input Layer**:\n",
    "    - Takes a 32x32 pixel grayscale image as input.\n",
    "\n",
    "2. **Convolutional Layers**:\n",
    "    - The first convolutional layer (C1) has 6 filters of size 5x5, resulting in 6 feature maps of size 28x28.\n",
    "    - The second convolutional layer (C3) has 16 filters, each connected to a subset of the 6 input feature maps, resulting in 16 feature maps of size 10x10.\n",
    "\n",
    "3. **Pooling Layers**:\n",
    "    - The first pooling layer (S2) performs average pooling on each of the 6 feature maps from the C1 layer, reducing their size to 14x14.\n",
    "    - The second pooling layer (S4) performs average pooling on each of the 16 feature maps from the C3 layer, reducing their size to 5x5.\n",
    "\n",
    "4. **Fully Connected Layers**:\n",
    "    - The first fully connected layer (C5) has 120 units.\n",
    "    - The second fully connected layer (F6) has 84 units.\n",
    "    - The output layer has 10 units, corresponding to the 10 digit classes (0-9).\n",
    "\n",
    "### Contribution to the Development of CNNs\n",
    "\n",
    "1. **Innovative Architecture**:\n",
    "    - LeNet-5 introduced several architectural innovations, such as the use of convolutional and pooling layers, which are fundamental to modern CNNs.\n",
    "\n",
    "2. **Hierarchical Feature Learning**:\n",
    "    - LeNet-5 demonstrated the power of hierarchical feature learning, where early layers capture low-level features like edges, and deeper layers capture more complex patterns.\n",
    "\n",
    "3. **Efficient Computation**:\n",
    "    - By using parameter sharing and local connections, LeNet-5 significantly reduced the number of parameters compared to fully connected networks, making training feasible.\n",
    "\n",
    "4. **Success in Handwritten Digit Recognition**:\n",
    "    - LeNet-5 achieved remarkable success in handwritten digit recognition tasks, outperforming traditional machine learning methods. This success helped establish CNNs as a powerful tool for image processing tasks.\n",
    "\n",
    "5. **Foundation for Modern CNNs**:\n",
    "    - The principles and architecture of LeNet-5 laid the foundation for more complex and deeper CNN architectures, such as AlexNet, VGG, and ResNet, which have achieved state-of-the-art performance in various computer vision tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. What is AlexNet, and why was it a breakthrough in deep learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet is a deep convolutional neural network that made significant strides in the field of deep learning and computer vision. It was developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, and it won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012 by a large margin.\n",
    "\n",
    "### Key Features of AlexNet\n",
    "\n",
    "1. **Deep Architecture**:\n",
    "    - AlexNet has a deeper architecture compared to earlier neural networks, consisting of eight layers: five convolutional layers followed by three fully connected layers.\n",
    "\n",
    "2. **ReLU Activation Functions**:\n",
    "    - It introduced the use of Rectified Linear Units (ReLUs) instead of traditional activation functions like sigmoid or tanh, which helped in faster training by mitigating the vanishing gradient problem.\n",
    "\n",
    "3. **Dropout Regularization**:\n",
    "    - AlexNet incorporated dropout as a regularization technique in the fully connected layers to prevent overfitting, which was a significant innovation at the time.\n",
    "\n",
    "4. **Data Augmentation**:\n",
    "    - The model employed data augmentation techniques such as random cropping, flipping, and color perturbations to artificially increase the size and diversity of the training dataset, improving generalization.\n",
    "\n",
    "5. **GPU Utilization**:\n",
    "    - It leveraged the power of Graphics Processing Units (GPUs) for training, which drastically reduced training time and enabled handling large-scale datasets.\n",
    "\n",
    "6. **Local Response Normalization**:\n",
    "    - The network used Local Response Normalization (LRN) after ReLU activations to enhance the generalization capability.\n",
    "\n",
    "### Why AlexNet Was a Breakthrough\n",
    "\n",
    "1. **Performance on ImageNet**:\n",
    "    - AlexNet achieved a top-5 error rate of 15.3%, which was a significant improvement over the second-best entry that had an error rate of 26.2% in the ILSVRC 2012 competition. This substantial margin demonstrated the effectiveness of deep learning.\n",
    "\n",
    "2. **Catalyst for Deep Learning Research**:\n",
    "    - The success of AlexNet brought deep learning into the spotlight, leading to a surge in research and development in the field. It showed that deep neural networks could outperform traditional machine learning techniques in complex tasks.\n",
    "\n",
    "3. **Advancements in Hardware Utilization**:\n",
    "    - By using GPUs for training, AlexNet showcased the potential of leveraging hardware advancements to train deeper and more complex models efficiently.\n",
    "\n",
    "4. **Foundation for Modern Architectures**:\n",
    "    - AlexNet laid the groundwork for more advanced deep learning architectures such as VGG, GoogLeNet, and ResNet. Its architectural innovations and training methodologies influenced many subsequent models.\n",
    "\n",
    "5. **Wide Application**:\n",
    "    - The principles and techniques introduced by AlexNet have been applied to various domains beyond image classification, including object detection, segmentation, and even in areas like natural language processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. What is VGGNet, and how does it differ from AlexNet ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet, or Visual Geometry Group Network, is another influential deep learning architecture developed by the Visual Geometry Group from the University of Oxford. It gained significant attention for its simplicity and effectiveness in image classification tasks, particularly in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014.\n",
    "\n",
    "### Key Features of VGGNet\n",
    "\n",
    "1. **Deeper Architecture**:\n",
    "    - VGGNet is characterized by its use of very deep networks. The most common versions are VGG-16 and VGG-19, with 16 and 19 layers, respectively.\n",
    "\n",
    "2. **Small Convolutional Filters**:\n",
    "    - Unlike AlexNet's larger filters, VGGNet uses small 3x3 convolutional filters throughout the network. This design choice allows the network to have more depth while keeping the number of parameters manageable.\n",
    "\n",
    "3. **Uniform Architecture**:\n",
    "    - VGGNet follows a uniform architecture where each convolutional layer is followed by a ReLU activation and pooling layer. The depth of the network increases by stacking these layers in a consistent pattern.\n",
    "\n",
    "4. **Fully Connected Layers**:\n",
    "    - Towards the end of the network, VGGNet employs three fully connected layers before the final softmax output layer.\n",
    "\n",
    "### Differences Between VGGNet and AlexNet\n",
    "\n",
    "1. **Depth**:\n",
    "    - **AlexNet**: Consists of 8 layers (5 convolutional layers + 3 fully connected layers).\n",
    "    - **VGGNet**: Is significantly deeper, with VGG-16 having 16 layers and VGG-19 having 19 layers.\n",
    "\n",
    "2. **Filter Size**:\n",
    "    - **AlexNet**: Uses larger filters (e.g., 11x11 and 5x5).\n",
    "    - **VGGNet**: Uses smaller 3x3 filters, which helps in capturing fine-grained details.\n",
    "\n",
    "3. **Architecture Uniformity**:\n",
    "    - **AlexNet**: Has a more varied architecture with different filter sizes and strides.\n",
    "    - **VGGNet**: Maintains a more uniform architecture with consistent use of 3x3 filters and pooling layers.\n",
    "\n",
    "4. **Performance**:\n",
    "    - **AlexNet**: Demonstrated the potential of deep learning on large-scale datasets and won the ILSVRC 2012.\n",
    "    - **VGGNet**: Achieved high performance in the ILSVRC 2014, particularly due to its depth and small filters, which helped in capturing complex patterns.\n",
    "\n",
    "5. **Training Complexity**:\n",
    "    - **AlexNet**: Was trained using two GPUs due to its architecture.\n",
    "    - **VGGNet**: Despite its depth, it was designed to be simple, making it easier to implement and train on modern GPUs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. What is GoogLeNet, and what is its main innovation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GoogLeNet, also known as Inception, is a pioneering deep learning architecture developed by researchers at Google. It won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2014. Its main innovation lies in the introduction of the **Inception module**. Let's dive into its key features:\n",
    "\n",
    "### Key Features of GoogLeNet\n",
    "\n",
    "1. **Inception Modules**:\n",
    "    - The Inception module allows the network to perform convolutions with multiple filter sizes (1x1, 3x3, 5x5) in parallel, capturing features at different scales. This parallelism enables the network to be both wide and deep, improving its ability to capture complex patterns in the data.\n",
    "\n",
    "2. **1x1 Convolutions**:\n",
    "    - GoogLeNet uses 1x1 convolutions within the Inception modules to reduce the dimensionality of the feature maps before applying the more computationally expensive 3x3 and 5x5 convolutions. This helps in reducing the number of parameters and the computational cost.\n",
    "\n",
    "3. **Depth and Efficiency**:\n",
    "    - Although it is a deep network with 22 layers, GoogLeNet is efficient due to the Inception modules and the use of 1x1 convolutions. This efficiency makes it possible to train deeper networks without excessive computational resources.\n",
    "\n",
    "4. **Global Average Pooling**:\n",
    "    - Instead of using fully connected layers at the end of the network, GoogLeNet employs global average pooling. This reduces the number of parameters and helps mitigate overfitting by averaging the feature maps.\n",
    "\n",
    "5. **Auxiliary Classifiers**:\n",
    "    - To address the vanishing gradient problem and improve the training process, GoogLeNet includes auxiliary classifiers. These additional output layers are connected to intermediate layers of the network and provide extra gradient signals during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. What is ResNet, and what problem does it solve ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet, or Residual Network, is a groundbreaking deep learning architecture introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. It was a major milestone in the development of deep neural networks and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2015. The main innovation of ResNet is its ability to train very deep networks by addressing the problem of vanishing gradients.\n",
    "\n",
    "### Key Features of ResNet\n",
    "\n",
    "1. **Residual Learning**:\n",
    "    - The core idea behind ResNet is the use of residual blocks, which allow the network to learn residual functions with reference to the layer inputs. Instead of directly learning a desired mapping, the network learns the difference (residual) between the input and the output.\n",
    "\n",
    "2. **Residual Blocks**:\n",
    "    - Each residual block consists of a few convolutional layers with a shortcut (skip connection) that bypasses these layers and adds the input directly to the output. This shortcut connection helps in mitigating the vanishing gradient problem.\n",
    "\n",
    "3. **Deep Architecture**:\n",
    "    - ResNet allows for the training of very deep networks with hundreds or even thousands of layers. The most common versions are ResNet-18, ResNet-34, ResNet-50, ResNet-101, and ResNet-152, where the number indicates the depth of the network.\n",
    "\n",
    "4. **Skip Connections**:\n",
    "    - The skip connections, or shortcuts, enable the gradients to flow directly through the network, making it easier to train deep models and improving the convergence rate.\n",
    "\n",
    "### The Problem ResNet Solves\n",
    "\n",
    "1. **Vanishing Gradient Problem**:\n",
    "    - In very deep neural networks, the gradients of the loss function can become very small during backpropagation, leading to slow convergence or even stopping the training process. This is known as the vanishing gradient problem.\n",
    "    - ResNet's skip connections allow gradients to bypass several layers, effectively solving this issue by maintaining strong gradient signals throughout the network.\n",
    "\n",
    "2. **Training Deep Networks**:\n",
    "    - Prior to ResNet, it was challenging to train very deep networks because they tended to suffer from degradation problems where the accuracy got saturated and then degraded rapidly with the increase in network depth.\n",
    "    - ResNet makes it feasible to train networks with a large number of layers by enabling more efficient gradient propagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. What is DenseNet, and how does it differ from ResNet ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DenseNet, short for Densely Connected Convolutional Networks, is a deep learning architecture that builds on the successes of networks like ResNet. It was introduced by Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. DenseNet introduces a unique connectivity pattern that addresses some limitations of traditional deep networks.\n",
    "\n",
    "### Key Features of DenseNet\n",
    "\n",
    "1. **Dense Connectivity**:\n",
    "    - Unlike ResNet, where each layer is connected to its subsequent layer through identity connections, DenseNet connects each layer to every other layer in a feed-forward fashion. This means that the output of each layer is concatenated with the outputs of all previous layers and used as input for the subsequent layers.\n",
    "\n",
    "2. **Feature Reuse**:\n",
    "    - The dense connections ensure that feature maps learned by each layer are reused by subsequent layers, leading to improved feature propagation and reduced redundancy. This reuse of features allows the network to be more compact and efficient.\n",
    "\n",
    "3. **Reduced Parameters**:\n",
    "    - By leveraging dense connections, DenseNet requires fewer parameters compared to traditional convolutional networks. This efficiency is achieved by reducing the need for a large number of filters in each layer.\n",
    "\n",
    "4. **Improved Gradient Flow**:\n",
    "    - The dense connections facilitate better gradient flow during backpropagation, which helps in training very deep networks without encountering the vanishing gradient problem.\n",
    "\n",
    "### Differences Between DenseNet and ResNet\n",
    "\n",
    "1. **Connection Pattern**:\n",
    "    - **ResNet**: Uses residual blocks where each layer's output is added to the input of that block through identity connections (skip connections).\n",
    "    - **DenseNet**: Uses dense blocks where each layer's output is concatenated with all preceding layers' outputs.\n",
    "\n",
    "2. **Feature Propagation**:\n",
    "    - **ResNet**: Relies on the addition of identity mappings to propagate features through the network.\n",
    "    - **DenseNet**: Propagates features by concatenating them, ensuring that each layer has access to the feature maps of all previous layers.\n",
    "\n",
    "3. **Parameter Efficiency**:\n",
    "    - **ResNet**: Generally requires more parameters due to the independent learning of features at each layer.\n",
    "    - **DenseNet**: Requires fewer parameters because of the dense connections and feature reuse.\n",
    "\n",
    "4. **Network Depth**:\n",
    "    - Both architectures can support very deep networks, but DenseNet's connectivity pattern often allows for even deeper architectures with improved performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. What are the main steps involved in training a CNN from scratch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a Convolutional Neural Network (CNN) from scratch involves several key steps. Here's an overview:\n",
    "\n",
    "### 1. **Data Collection and Preprocessing**\n",
    "- **Data Collection**: Gather a large dataset that is representative of the task at hand. For image tasks, this might include thousands of labeled images.\n",
    "- **Data Preprocessing**: Normalize the images (e.g., scale pixel values to a range of 0-1 or -1 to 1), resize them to a consistent size, and possibly augment them with techniques like rotation, flipping, and cropping to increase the dataset size and variability.\n",
    "\n",
    "### 2. **Designing the Network Architecture**\n",
    "- **Network Architecture**: Define the architecture of your CNN. This includes specifying the number of layers, types of layers (convolutional, pooling, fully connected), filter sizes, activation functions, etc.\n",
    "- **Initial Weights**: Initialize the weights of the network, often using techniques like Xavier or He initialization.\n",
    "\n",
    "### 3. **Choosing the Loss Function and Optimizer**\n",
    "- **Loss Function**: Select an appropriate loss function based on the task. For classification, cross-entropy loss is commonly used.\n",
    "- **Optimizer**: Choose an optimizer to update the network’s weights during training. Popular choices include Stochastic Gradient Descent (SGD) with momentum, Adam, and RMSprop.\n",
    "\n",
    "### 4. **Training the Network**\n",
    "- **Forward Propagation**: Pass the input data through the network to obtain predictions.\n",
    "- **Loss Calculation**: Compute the loss between the predicted output and the actual labels.\n",
    "- **Backward Propagation**: Calculate the gradients of the loss with respect to each weight using backpropagation.\n",
    "- **Weight Update**: Update the weights using the gradients and the chosen optimizer.\n",
    "- **Epochs and Batches**: Repeat the forward and backward propagation steps for multiple epochs, and update weights after processing each mini-batch of the data.\n",
    "\n",
    "### 5. **Validation and Hyperparameter Tuning**\n",
    "- **Validation Set**: Use a validation set to evaluate the model’s performance after each epoch, helping to detect overfitting.\n",
    "- **Hyperparameter Tuning**: Experiment with different hyperparameters (learning rate, batch size, number of layers, etc.) to find the optimal configuration.\n",
    "\n",
    "### 6. **Model Evaluation**\n",
    "- **Test Set**: After training, evaluate the final model on a separate test set to gauge its performance on unseen data.\n",
    "- **Metrics**: Use metrics like accuracy, precision, recall, and F1-score to assess the model’s effectiveness.\n",
    "\n",
    "### 7. **Fine-tuning and Deployment**\n",
    "- **Fine-tuning**: If necessary, fine-tune the model by further training on a smaller learning rate or with additional data.\n",
    "- **Deployment**: Once satisfied with the model’s performance, deploy it for practical use. This might involve exporting the model to a format suitable for inference in a production environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------Practical------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement a basic convolution operation using a filter and a 5x5 image (matrix).\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convolve(image, kernel):\n",
    "    \"\"\"Performs a 2D convolution.\"\"\"\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "\n",
    "    pad_height = kernel_height // 2\n",
    "    pad_width = kernel_width // 2\n",
    "\n",
    "    padded_image = np.pad(image, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "    output = np.zeros_like(image)\n",
    "\n",
    "    for y in range(image_height):\n",
    "        for x in range(image_width):\n",
    "            roi = padded_image[y:y + kernel_height, x:x + kernel_width]\n",
    "            output[y, x] = np.sum(roi * kernel)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example  5 x 5 image\n",
    "image = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20],\n",
    "    [21, 22, 23, 24, 25]\n",
    "])\n",
    "\n",
    "kernel = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1, 8, -1],\n",
    "    [-1, -1, -1]\n",
    "])\n",
    "\n",
    "convolved_image = convolve(image, kernel)\n",
    "print(\"Convolved Image:\\n\", convolved_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement max pooling on a 4x4 feature map with a 2x2 window ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(feature_map, pool_size=(2, 2)):\n",
    "\n",
    "    if not isinstance(feature_map, np.ndarray) or feature_map.ndim != 2:\n",
    "        print(\"Error: Feature map must be a 2D numpy array.\")\n",
    "        return None\n",
    "\n",
    "    if not isinstance(pool_size, tuple) or len(pool_size) != 2 or not all(isinstance(dim, int) and dim > 0 for dim in pool_size):\n",
    "        print(\"Error: Pool size must be a tuple of two positive integers.\")\n",
    "        return None\n",
    "        \n",
    "    map_height, map_width = feature_map.shape\n",
    "    pool_height, pool_width = pool_size\n",
    "\n",
    "    if map_height < pool_height or map_width < pool_width:\n",
    "        print(\"Error: Pool size cannot be larger than feature map dimensions.\")\n",
    "        return None\n",
    "\n",
    "    pooled_height = map_height // pool_height\n",
    "    pooled_width = map_width // pool_width\n",
    "\n",
    "    pooled_map = np.zeros((pooled_height, pooled_width))\n",
    "\n",
    "    for y in range(pooled_height):\n",
    "        for x in range(pooled_width):\n",
    "            # Extract the region of interest (ROI)\n",
    "            roi = feature_map[y * pool_height:(y + 1) * pool_height, x * pool_width:(x + 1) * pool_width]\n",
    "            pooled_map[y, x] = np.max(roi)  # Take the maximum value\n",
    "\n",
    "    return pooled_map\n",
    "\n",
    "# Example usage:\n",
    "feature_map = np.array([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "pooled_map = max_pool(feature_map)\n",
    "\n",
    "if pooled_map is not None:\n",
    "    print(\"Feature Map:\\n\", feature_map)\n",
    "    print(\"\\nPooled Map:\\n\", pooled_map)\n",
    "\n",
    "feature_map2 = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [5, 6, 7, 8, 9],\n",
    "    [9, 10, 11, 12, 13],\n",
    "    [13, 14, 15, 16, 17]\n",
    "])\n",
    "\n",
    "pooled_map2 = max_pool(feature_map2)\n",
    "\n",
    "if pooled_map2 is not None:\n",
    "    print(\"\\nFeature Map 2:\\n\", feature_map2)\n",
    "    print(\"\\nPooled Map 2:\\n\", pooled_map2)\n",
    "\n",
    "pooled_map3 = max_pool(feature_map, (3,3))\n",
    "\n",
    "if pooled_map3 is not None:\n",
    "    print(\"\\nFeature Map:\\n\", feature_map)\n",
    "    print(\"\\nPooled Map 3:\\n\", pooled_map3)\n",
    "\n",
    "pooled_map4 = max_pool(feature_map, (5,5))\n",
    "\n",
    "if pooled_map4 is not None:\n",
    "    print(\"\\nFeature Map:\\n\", feature_map)\n",
    "    print(\"\\nPooled Map 4:\\n\", pooled_map4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Implement the ReLU activation function on a feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(feature_map):\n",
    "    if not isinstance(feature_map, np.ndarray):\n",
    "        print(\"Error: Input must be a numpy array.\")\n",
    "        return None\n",
    "    return np.maximum(0, feature_map)\n",
    "\n",
    "# Example:\n",
    "feature_map = np.array([\n",
    "    [-1, 2, -3, 4],\n",
    "    [5, -6, 7, -8],\n",
    "    [-9, 10, -11, 12]\n",
    "])\n",
    "\n",
    "activated_map = relu(feature_map)\n",
    "\n",
    "if activated_map is not None:\n",
    "    print(\"Original Feature Map:\\n\", feature_map)\n",
    "    print(\"\\nReLU Activated Feature Map:\\n\", activated_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a simple CNN model with one convolutional layer and a fully connected layer, using random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def convolve(image, kernel):\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    pad_height = kernel_height // 2\n",
    "    pad_width = kernel_width // 2\n",
    "    padded_image = np.pad(image, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "    output = np.zeros_like(image)\n",
    "    for y in range(image_height):\n",
    "        for x in range(image_width):\n",
    "            roi = padded_image[y:y + kernel_height, x:x + kernel_width]\n",
    "            output[y, x] = np.sum(roi * kernel)\n",
    "    return output\n",
    "\n",
    "def flatten(x):\n",
    "  return x.flatten()\n",
    "\n",
    "# Model definition\n",
    "def simple_cnn(input_image, kernel, weights, bias):\n",
    "    \"\"\"A simple CNN with one conv layer and one FC layer.\"\"\"\n",
    "    conv_output = convolve(input_image, kernel)\n",
    "    activated_output = relu(conv_output)\n",
    "    flattened_output = flatten(activated_output)\n",
    "    fc_output = np.dot(flattened_output, weights) + bias\n",
    "    return fc_output\n",
    "\n",
    "# Example usage with random data\n",
    "input_image = np.random.rand(5, 5)  # 5x5 input image\n",
    "kernel = np.random.rand(3, 3)      # 3x3 kernel\n",
    "weights = np.random.rand(input_image.size) # weights for fully connected layer\n",
    "bias = np.random.rand() # bias for fully connected layer\n",
    "\n",
    "output = simple_cnn(input_image, kernel, weights, bias)\n",
    "\n",
    "print(\"Input Image:\\n\", input_image)\n",
    "print(\"\\nKernel:\\n\", kernel)\n",
    "print(\"\\nWeights:\\n\", weights)\n",
    "print(\"\\nBias:\\n\", bias)\n",
    "print(\"\\nOutput:\\n\", output)\n",
    "\n",
    "\n",
    "input_image2 = np.random.rand(7, 7)  # 7x7 input image\n",
    "kernel2 = np.random.rand(2, 2)      # 2x2 kernel\n",
    "weights2 = np.random.rand(input_image2.size) # weights for fully connected layer\n",
    "bias2 = np.random.rand() # bias for fully connected layer\n",
    "\n",
    "output2 = simple_cnn(input_image2, kernel2, weights2, bias2)\n",
    "\n",
    "print(\"\\nInput Image 2:\\n\", input_image2)\n",
    "print(\"\\nKernel 2:\\n\", kernel2)\n",
    "print(\"\\nWeights 2:\\n\", weights2)\n",
    "print(\"\\nBias 2:\\n\", bias2)\n",
    "print(\"\\nOutput 2:\\n\", output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Generate a synthetic dataset using random noise and train a simple CNN model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def relu(x):\n",
    "    return tf.maximum(0, x)\n",
    "\n",
    "def convolve(image, kernel):\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    pad_height = kernel_height // 2\n",
    "    pad_width = kernel_width // 2\n",
    "    padded_image = np.pad(image, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "    output = np.zeros_like(image)\n",
    "    for y in range(image_height):\n",
    "        for x in range(image_width):\n",
    "            roi = padded_image[y:y + kernel_height, x:x + kernel_width]\n",
    "            output[y, x] = np.sum(roi * kernel)\n",
    "    return tf.convert_to_tensor(output, dtype=tf.float32)\n",
    "\n",
    "def flatten(x):\n",
    "    return tf.reshape(x, [-1])\n",
    "\n",
    "def simple_cnn(input_image, kernel, weights, bias):\n",
    "    conv_output = convolve(input_image, kernel)\n",
    "    activated_output = relu(conv_output)\n",
    "    flattened_output = flatten(activated_output)\n",
    "    fc_output = tf.matmul(tf.expand_dims(flattened_output, axis=0), tf.expand_dims(weights, axis=1)) + bias\n",
    "    return fc_output\n",
    "\n",
    "# Generate synthetic dataset\n",
    "num_samples = 1000\n",
    "image_size = 8\n",
    "X = np.random.rand(num_samples, image_size, image_size).astype(np.float32)\n",
    "y = np.random.randint(0, 2, num_samples).astype(np.float32)\n",
    "\n",
    "# Initialize model parameters as TensorFlow Variables\n",
    "kernel = tf.Variable(np.random.rand(3, 3).astype(np.float32))\n",
    "weights = tf.Variable(np.random.rand((image_size - 3 + 1)**2).astype(np.float32))\n",
    "bias = tf.Variable(np.random.rand().astype(np.float32))\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Training loop with TensorFlow GradientTape\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(num_samples):\n",
    "        with tf.GradientTape() as tape:\n",
    "            input_image = tf.convert_to_tensor(X[i], dtype=tf.float32)\n",
    "            target = y[i]\n",
    "            output = simple_cnn(input_image, kernel, weights, bias)\n",
    "            loss = tf.square(output - target)  # Mean Squared Error\n",
    "        \n",
    "        gradients = tape.gradient(loss, [kernel, weights, bias])\n",
    "        optimizer.apply_gradients(zip(gradients, [kernel, weights, bias]))\n",
    "\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/num_samples}\")\n",
    "\n",
    "# Example prediction (after \"training\")\n",
    "test_image = tf.convert_to_tensor(np.random.rand(image_size, image_size).astype(np.float32))\n",
    "prediction = simple_cnn(test_image, kernel, weights, bias)\n",
    "print(\"\\nTest Image:\\n\", test_image)\n",
    "print(\"\\nPrediction:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create a simple CNN using Keras with one convolution layer and a max-pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">54,090</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m54,090\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,410</span> (212.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,410\u001b[0m (212.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,410</span> (212.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,410\u001b[0m (212.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.1069 - loss: 2.3545 - val_accuracy: 0.1300 - val_loss: 2.3058\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1473 - loss: 2.2859 - val_accuracy: 0.0800 - val_loss: 2.3174\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1789 - loss: 2.2153 - val_accuracy: 0.0300 - val_loss: 2.3355\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4457 - loss: 2.1207 - val_accuracy: 0.0600 - val_loss: 2.3516\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3762 - loss: 2.0399 - val_accuracy: 0.1200 - val_loss: 2.3323\n",
      "Test Loss: 2.3323\n",
      "Test Accuracy: 0.1200\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),  # Input layer (adjust shape as needed)\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"), # Convolutional layer\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), # Max pooling layer\n",
    "        layers.Flatten(), # Flatten the output for the Dense layer\n",
    "        layers.Dense(10, activation=\"softmax\"), # Output layer with softmax for classification\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Generate dummy data for demonstration (replace with your actual data)\n",
    "num_samples = 1000\n",
    "img_height, img_width = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "X_train = np.random.rand(num_samples, img_height, img_width, 1)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "X_test = np.random.rand(100, img_height, img_width, 1)\n",
    "y_test = np.random.randint(0, num_classes, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test,y_test)) # Train for 5 epochs\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write a code to add a fully connected layer after the convolution and max-pooling layers in a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">692,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv_1 (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc_1 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m692,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.1078 - loss: 2.3464 - val_accuracy: 0.0800 - val_loss: 2.3184\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1226 - loss: 2.2921 - val_accuracy: 0.0800 - val_loss: 2.3148\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.1420 - loss: 2.2479 - val_accuracy: 0.1200 - val_loss: 2.3341\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.2483 - loss: 2.1830 - val_accuracy: 0.1100 - val_loss: 2.3246\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3466 - loss: 2.0719 - val_accuracy: 0.1000 - val_loss: 2.3203\n",
      "Test Loss: 2.3203\n",
      "Test Accuracy: 0.1000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_cnn_with_fc(input_shape, num_classes):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", name=\"conv_1\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pool\"),\n",
    "            layers.Flatten(name=\"flatten\"),  # Flatten before the fully connected layer\n",
    "            layers.Dense(128, activation=\"relu\", name=\"fc_1\"),  # Fully connected layer\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output\"),  # Output layer\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (28, 28, 1)  # Example input shape (e.g., MNIST images)\n",
    "num_classes = 10  # Example number of classes (e.g., digits 0-9)\n",
    "\n",
    "model = create_cnn_with_fc(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Generate dummy data for demonstration (replace with your actual data)\n",
    "num_samples = 1000\n",
    "img_height, img_width = input_shape[0], input_shape[1]\n",
    "\n",
    "X_train = np.random.rand(num_samples, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_train = np.random.randint(0, num_classes, num_samples)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes).astype(np.float32)\n",
    "\n",
    "X_test = np.random.rand(100, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_test = np.random.randint(0, num_classes, 100)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes).astype(np.float32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.  Write a code to add  batch normalization to a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_cnn_with_batchnorm(input_shape, num_classes):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", name=\"conv_1\"),\n",
    "            layers.BatchNormalization(name=\"batch_norm_1\"), # Batch Normalization after Conv2D\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pool\"),\n",
    "            layers.Flatten(name=\"flatten\"),\n",
    "            layers.Dense(128, activation=\"relu\", name=\"fc_1\"),\n",
    "            layers.BatchNormalization(name=\"batch_norm_fc\"), # Batch Normalization after FC layer\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "model = create_cnn_with_batchnorm(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Generate dummy data (replace with your actual data)\n",
    "num_samples = 1000\n",
    "img_height, img_width = input_shape[0], input_shape[1]\n",
    "\n",
    "X_train = np.random.rand(num_samples, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_train = keras.utils.to_categorical(np.random.randint(0, num_classes, num_samples), num_classes).astype(np.float32)\n",
    "\n",
    "X_test = np.random.rand(100, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_test = keras.utils.to_categorical(np.random.randint(0, num_classes, 100), num_classes).astype(np.float32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write a code to add dropout regularization to a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_cnn_with_dropout(input_shape, num_classes, dropout_rate=0.5):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", name=\"conv_1\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pool\"),\n",
    "            layers.Flatten(name=\"flatten\"),\n",
    "            layers.Dropout(dropout_rate, name=\"dropout_1\"),  # Dropout after Flatten\n",
    "            layers.Dense(128, activation=\"relu\", name=\"fc_1\"),\n",
    "            layers.Dropout(dropout_rate, name=\"dropout_2\"), # Dropout after FC layer\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "dropout_rate = 0.5 # You can experiment with different dropout rates\n",
    "\n",
    "model = create_cnn_with_dropout(input_shape, num_classes, dropout_rate)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Generate dummy data (replace with your actual data)\n",
    "num_samples = 1000\n",
    "img_height, img_width = input_shape[0], input_shape[1]\n",
    "\n",
    "X_train = np.random.rand(num_samples, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_train = keras.utils.to_categorical(np.random.randint(0, num_classes, num_samples), num_classes).astype(np.float32)\n",
    "\n",
    "X_test = np.random.rand(100, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_test = keras.utils.to_categorical(np.random.randint(0, num_classes, 100), num_classes).astype(np.float32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Write a code to print the architecture of the VGG16 model in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Create the VGG16 model\n",
    "model = VGG16(weights='imagenet')  # Load pre-trained weights\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "# Accessing layers and their properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Write a code to plot the accuracy and loss graphs after training a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - accuracy: 0.1125 - loss: 2.3914 - val_accuracy: 0.0400 - val_loss: 2.3352\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1068 - loss: 2.3116 - val_accuracy: 0.1200 - val_loss: 2.3059\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1270 - loss: 2.2907 - val_accuracy: 0.0900 - val_loss: 2.3153\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.1356 - loss: 2.2881 - val_accuracy: 0.0700 - val_loss: 2.3180\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2284 - loss: 2.2492 - val_accuracy: 0.0900 - val_loss: 2.2950\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2867 - loss: 2.2146 - val_accuracy: 0.1300 - val_loss: 2.3144\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3409 - loss: 2.1523 - val_accuracy: 0.1400 - val_loss: 2.3279\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.2808 - loss: 2.0798 - val_accuracy: 0.1100 - val_loss: 2.3481\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3979 - loss: 2.0034 - val_accuracy: 0.1000 - val_loss: 2.3648\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4351 - loss: 1.8936 - val_accuracy: 0.0900 - val_loss: 2.4519\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def create_cnn(input_shape, num_classes):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", name=\"conv_1\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pool\"),\n",
    "            layers.Flatten(name=\"flatten\"),\n",
    "            layers.Dense(128, activation=\"relu\", name=\"fc_1\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "\n",
    "model = create_cnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Generate dummy data (replace with your actual data)\n",
    "num_samples = 1000\n",
    "img_height, img_width = input_shape[0], input_shape[1]\n",
    "\n",
    "X_train = np.random.rand(num_samples, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_train = keras.utils.to_categorical(np.random.randint(0, num_classes, num_samples), num_classes).astype(np.float32)\n",
    "\n",
    "X_test = np.random.rand(100, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_test = keras.utils.to_categorical(np.random.randint(0, num_classes, 100), num_classes).astype(np.float32)\n",
    "\n",
    "# Train the model and store the training history\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Write a code to print the architecture of the ResNet50 model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Create the ResNet50 model\n",
    "model = ResNet50(weights='imagenet')  # Load pre-trained weights. Use weights=None for no weights\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Write a code to train a basic CNN model and print the training loss and accuracy after each epoch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.0848 - loss: 2.3860 - val_accuracy: 0.1200 - val_loss: 2.3114\n",
      "Training Loss: 2.3624, Training Accuracy: 0.0880\n",
      "Validation Loss: 2.3114, Validation Accuracy: 0.1200\n",
      "--------------------\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.1181 - loss: 2.2942 - val_accuracy: 0.1000 - val_loss: 2.3147\n",
      "Training Loss: 2.2954, Training Accuracy: 0.1190\n",
      "Validation Loss: 2.3147, Validation Accuracy: 0.1000\n",
      "--------------------\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.1462 - loss: 2.2677 - val_accuracy: 0.1200 - val_loss: 2.3049\n",
      "Training Loss: 2.2671, Training Accuracy: 0.1530\n",
      "Validation Loss: 2.3049, Validation Accuracy: 0.1200\n",
      "--------------------\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.1990 - loss: 2.2234 - val_accuracy: 0.0800 - val_loss: 2.3150\n",
      "Training Loss: 2.2234, Training Accuracy: 0.1970\n",
      "Validation Loss: 2.3150, Validation Accuracy: 0.0800\n",
      "--------------------\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.2684 - loss: 2.1512 - val_accuracy: 0.1200 - val_loss: 2.3081\n",
      "Training Loss: 2.1411, Training Accuracy: 0.2930\n",
      "Validation Loss: 2.3081, Validation Accuracy: 0.1200\n",
      "--------------------\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.4455 - loss: 2.0269 - val_accuracy: 0.1100 - val_loss: 2.3459\n",
      "Training Loss: 2.0170, Training Accuracy: 0.4240\n",
      "Validation Loss: 2.3459, Validation Accuracy: 0.1100\n",
      "--------------------\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.4907 - loss: 1.8951 - val_accuracy: 0.1000 - val_loss: 2.3682\n",
      "Training Loss: 1.8796, Training Accuracy: 0.5000\n",
      "Validation Loss: 2.3682, Validation Accuracy: 0.1000\n",
      "--------------------\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.6545 - loss: 1.6995 - val_accuracy: 0.1400 - val_loss: 2.4743\n",
      "Training Loss: 1.6595, Training Accuracy: 0.6700\n",
      "Validation Loss: 2.4743, Validation Accuracy: 0.1400\n",
      "--------------------\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6867 - loss: 1.4981 - val_accuracy: 0.0800 - val_loss: 2.5221\n",
      "Training Loss: 1.4449, Training Accuracy: 0.7290\n",
      "Validation Loss: 2.5221, Validation Accuracy: 0.0800\n",
      "--------------------\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7364 - loss: 1.2593 - val_accuracy: 0.1200 - val_loss: 2.4965\n",
      "Training Loss: 1.2204, Training Accuracy: 0.7510\n",
      "Validation Loss: 2.4965, Validation Accuracy: 0.1200\n",
      "--------------------\n",
      "Final Test Loss: 2.4965\n",
      "Final Test Accuracy: 0.1200\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "def create_cnn(input_shape, num_classes):\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", name=\"conv_1\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), name=\"max_pool\"),\n",
    "            layers.Flatten(name=\"flatten\"),\n",
    "            layers.Dense(128, activation=\"relu\", name=\"fc_1\"),\n",
    "            layers.Dense(num_classes, activation=\"softmax\", name=\"output\"),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "input_shape = (28, 28, 1)  # Example: MNIST-like input\n",
    "num_classes = 10\n",
    "\n",
    "model = create_cnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Generate dummy data (replace with your actual data)\n",
    "num_samples = 1000\n",
    "img_height, img_width = input_shape[0], input_shape[1]\n",
    "\n",
    "X_train = np.random.rand(num_samples, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_train = keras.utils.to_categorical(np.random.randint(0, num_classes, num_samples), num_classes).astype(np.float32)\n",
    "\n",
    "X_test = np.random.rand(100, img_height, img_width, input_shape[2]).astype(np.float32)\n",
    "y_test = keras.utils.to_categorical(np.random.randint(0, num_classes, 100), num_classes).astype(np.float32)\n",
    "\n",
    "# Train the model and print loss/accuracy after each epoch\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    history = model.fit(X_train, y_train, epochs=1, batch_size=batch_size, verbose=1, validation_data=(X_test, y_test))  # Train for 1 epoch at a time\n",
    "    loss = history.history['loss'][0]\n",
    "    accuracy = history.history['accuracy'][0]\n",
    "    val_loss = history.history['val_loss'][0]\n",
    "    val_accuracy = history.history['val_accuracy'][0]\n",
    "    print(f\"Training Loss: {loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "# Final evaluation\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Final Test Loss: {loss:.4f}\")\n",
    "print(f\"Final Test Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
